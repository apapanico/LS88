{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Baseball-Run-Values-from-Regression\" data-toc-modified-id=\"Baseball-Run-Values-from-Regression-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Baseball Run Values from Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Our-first-regression-model\" data-toc-modified-id=\"Our-first-regression-model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Our first regression model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stolen-Base-Breakeven-Probability\" data-toc-modified-id=\"Stolen-Base-Breakeven-Probability-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Stolen Base Breakeven Probability</a></span></li><li><span><a href=\"#Residuals\" data-toc-modified-id=\"Residuals-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Residuals</a></span></li></ul></li><li><span><a href=\"#Are-Ks-more-costly-than-other-outs?\" data-toc-modified-id=\"Are-Ks-more-costly-than-other-outs?-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Are Ks more costly than other outs?</a></span></li><li><span><a href=\"#What-happens-if-we-only-use-a-year-of-data?\" data-toc-modified-id=\"What-happens-if-we-only-use-a-year-of-data?-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>What happens if we only use a year of data?</a></span></li><li><span><a href=\"#What-happens-if-we-only-use-a-single-variable?\" data-toc-modified-id=\"What-happens-if-we-only-use-a-single-variable?-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>What happens if we only use a single variable?</a></span></li></ul></li><li><span><a href=\"#Four-Factor-Model\" data-toc-modified-id=\"Four-Factor-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Four Factor Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Four-Factors-and-Winning-Pct\" data-toc-modified-id=\"Four-Factors-and-Winning-Pct-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Four Factors and Winning Pct</a></span></li><li><span><a href=\"#Four-Factors-and-the-log-Rating-Ratio\" data-toc-modified-id=\"Four-Factors-and-the-log-Rating-Ratio-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Four Factors and the log Rating Ratio</a></span><ul class=\"toc-item\"><li><span><a href=\"#As-before,-what-if-only-include-one-variable-in-the-regression?\" data-toc-modified-id=\"As-before,-what-if-only-include-one-variable-in-the-regression?-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>As before, what if only include one variable in the regression?</a></span></li></ul></li><li><span><a href=\"#By-Games\" data-toc-modified-id=\"By-Games-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>By Games</a></span></li></ul></li><li><span><a href=\"#Plus/Minus-Regression\" data-toc-modified-id=\"Plus/Minus-Regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Plus/Minus Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stint-data\" data-toc-modified-id=\"Stint-data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Stint data</a></span></li><li><span><a href=\"#Stint-Data-for-Regression\" data-toc-modified-id=\"Stint-Data-for-Regression-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Stint Data for Regression</a></span></li><li><span><a href=\"#Adjusted-Plus/Minus\" data-toc-modified-id=\"Adjusted-Plus/Minus-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Adjusted Plus/Minus</a></span></li><li><span><a href=\"#Penalizing-the-Least-Squares-Fit:-Regularized-Adjusted-Plus-Minus-(xRAPM)\" data-toc-modified-id=\"Penalizing-the-Least-Squares-Fit:-Regularized-Adjusted-Plus-Minus-(xRAPM)-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Penalizing the Least Squares Fit: Regularized Adjusted Plus Minus (xRAPM)</a></span></li><li><span><a href=\"#How-penalizing-the-coefficients-cleans-things-up\" data-toc-modified-id=\"How-penalizing-the-coefficients-cleans-things-up-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>How penalizing the coefficients cleans things up</a></span></li><li><span><a href=\"#Compare-to-ESPN's-RPM\" data-toc-modified-id=\"Compare-to-ESPN's-RPM-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Compare to ESPN's RPM</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Modeling\n",
    "\n",
    "This demo goes over regression modeling and how we can use it to compute run values and the four factor model like we've already seen.  We'll also see how we can use regression modeling to compute a sophisticated Plus/Minus Rating model that greatly improves on conventional Plus/Minus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from regression_helper import multiple_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseball Run Values from Regression\n",
    "\n",
    "Recall the formula for Linear Weights:\n",
    "$$\n",
    "  \\text{Runs Above Average} = .46\\cdot \\mathit{1B} + .80\\cdot \\mathit{2B} + 1.02\\cdot \\mathit{3B} + 1.40\\cdot \\mathit{HR} + .33\\cdot (\\mathit{BB} + \\mathit{HBP}) - .25\\cdot \\mathit{O}\n",
    "$$\n",
    "\n",
    "We directly computed the run values for the events through a simple and elegant computation with the play-by-play data.  But there's nothing that stops us from trying to compute the run values through regression.  LWTS is a linear model, after all.\n",
    "\n",
    "It turns out, using season level data for teams we can do pretty well estimating the run values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Similar to what we've seen before, we're goint to use the Lahman dataset but cleaned a bit for ease of use with our helper function.  In particular, some columns have been renamed, some extra have been computed, and many have been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lahman_teams.csv obtained from the lahman_main databank. \n",
    "# This table is a slight modification of the regular table.\n",
    "lahman = pd.read_csv(\"lahman_teams.csv\")\n",
    "lahman.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first regression model\n",
    "\n",
    "Let's build our first regression model.  We need to tell the function `multiple_regression` which is the dependent variable (the observation) and the independent variables (the inputs).\n",
    "\n",
    "The dependent variable is going to be Runs Above Average and the independent variables will be the events.\n",
    "\n",
    "Comparing the regression to the run values we obtained earlier, we find pretty similar results.  It's hard to argue wih the effectiveness of the regression.\n",
    "\n",
    "| Event | Run Value |\n",
    "| ----------------- |\n",
    "|  Out  |  -0.287   |\n",
    "|  1B   |   0.462   |\n",
    "|  2B   |   0.781   |\n",
    "|  3B   |   1.085   |\n",
    "|  HR   |   1.383   |\n",
    "|  BB   |   0.306   |\n",
    "|  HBP  |   0.336   |\n",
    "\n",
    "From FanGraphs, the run values for SB and CS are .2 and -(2 * run_per_out + 0.075) (generally about -.4).  Our findings align pretty well with that.\n",
    "\n",
    "We could have used additional variables for the regression.  We're a bit limited based on the Lahman dataset so we cannot distinguish between regular walks and intentional walks, or fielder's choice, or reaching base on an error.  Luckily we've got most of the events and the most important ones at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_vars = 'RAA'\n",
    "ind_vars = ['O', 'X1B', 'X2B', 'X3B', 'HR', 'BB', 'HBP', 'SB', 'CS']\n",
    "coefs, predictions, errors = multiple_regression(dep_vars, ind_vars, lahman)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stolen Base Breakeven Probability\n",
    "\n",
    "The breakeven probability for a stolen base tells us how likely a stolen base needs to be to make it an even proposition in terms of run expectancy.  Research has shown that some poorly constructed regression models can fail to provide a properly calibrated model with respect to the breakeven probability.  Our model is pretty close to what we should expect, which is about 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(coefs['CS']) / (coefs['SB'] + np.abs(coefs['CS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuals\n",
    "We can look a scatterplot between RAA and the errors from the regression.  The doesn't look eggregiously bad so it looks like we're doing a fair job of caputing run scoring with the events we have used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lahman['RAA'], errors, '.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are Ks more costly than other outs?\n",
    "\n",
    "Among other variables we could have used is the strikeout.  Presumably striking out and not putting the ball in play, even if it results in an out, should be less valuable.  So is there much of a distinction between regular outs and strikeouts?\n",
    "\n",
    "The evidence is not strong that it's hugely different in value but the diffence is slightly larger in magnitude than\n",
    "what we computed using play-by-play data.\n",
    "\n",
    "\n",
    "| Event | Run Value |\n",
    "| ----------------- |\n",
    "|  Out  |  -0.287   |\n",
    "|   K   |  -0.292   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_vars_with_K = ['O_nonK', 'SO', 'X1B', 'X2B', 'X3B', 'HR', 'BB', 'HBP', 'SB', 'CS']\n",
    "coefs_with_K, _, _ = multiple_regression(dep_vars, ind_vars_with_K, lahman)\n",
    "coefs_with_K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens if we only use a year of data?\n",
    "\n",
    "We used all years since 2000 to build our regression.  What if we want to compute the run values for a single year, say 2016?  Let's sluff off the rest of the data and run our regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lahman_2016 = lahman.loc[lahman['yearID'] == 2016].copy()\n",
    "lahman_2016['RAA'] = lahman_2016['R'] - lahman_2016['R'].mean()\n",
    "coefs_2016, _, _ = multiple_regression(dep_vars, ind_vars, lahman_2016)\n",
    "coefs_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end result is not good.  We don't know the ground truth but we have a good idea of where things should be and in this case, some of these values are ludicrous.  The value of a double is way off, especially given that it's worth more than a triple.  The values for HBP and BB are out of whack too.  Most alarmingly, the value for CS is now positive.\n",
    "\n",
    "So what happened?  \n",
    "\n",
    "Not enough data.  That's pretty much it.  One season of MLB has only 30 observations and we tried to estimate 9 coeffients.  30 data points would possibly be okay if we wanted to measure 1 effect.  But 9 simultaneous effects?  No way.\n",
    "\n",
    "The play-by-play method worked for a single season but this regression approach requires multiple years.  This is not great if we want to capture changing run environments.  A potential solution (if we wanted to continue with regression modeling) would be to build a regression using the play-by-play data.  That would be enough data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens if we only use a single variable?\n",
    "\n",
    "Let's return to our data for the 2000s but now we'll explore an important phenomenon with regression modeling: misspecification.\n",
    "\n",
    "The underlying mathematical theory says that if you have all the independent variables that the observation depends on (and among other assumptions the true model is linear), regression modeling will properly estimate the coefficients of the model.\n",
    "\n",
    "So far we've seen regression models that do pretty well because we're doing a pretty good job of specifying the model.  Let's see just how the regression could have produced junk results if we did not properly specify the regression model.\n",
    "\n",
    "We specify an constant term in `multiple_regression` because it provides an intercept to the regression line, which is very much needed as indicated by the scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_vars = 'RAA'\n",
    "ind_vars = 'X2B'\n",
    "coefs, predictions, errors = multiple_regression(dep_vars, ind_vars, lahman, constant=True)\n",
    "lahman.plot.scatter(x=ind_vars, y=dep_vars)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it feels like we should have been able to estimate the individual effects of the events, the poor results show that the simultaneous effects of the different events make it so that you definitely need to incorporate all the events to get proper results.\n",
    "\n",
    "This is huge part of any statistical study using regression: you need to collect as much information as you can that likely is relevant because if you fail to account for relevant information, your results will likely be corrupted and erroneous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Factor Model\n",
    "\n",
    "Recall Dean Oliver's four factor model for basketball:\n",
    "\\begin{align*}\n",
    "  \\text{Team Performance} & = .4 \\cdot Z(\\mathit{eFG\\%} -  \\mathit{eFG\\%}_{\\text{Opp}}) \\\\\n",
    "  & \\quad - .25 \\cdot Z(\\text{Turnover Rate} - \\text{Turnover Rate}_{\\text{Opp}}) \\\\\n",
    "  & \\quad + .2 \\cdot Z(\\mathit{OREB\\%} -  \\mathit{OREB\\%}_{\\text{Opp}}) \\\\\n",
    "  & \\quad  + .15 \\cdot Z(\\text{FT Rate} - \\text{FT Rate}_{\\text{Opp}})\n",
    "\\end{align*}\n",
    "\n",
    "The model tried to explain team performance through four fundamental factors.  Dean Oliver prescribed his own relative importance to the factors as 40% for efficient shooting, 25% for turnovers, 20% for rebounding, and 15% for free throw attempts.   Where did Dean Oliver get those values?  Are they the best?\n",
    "\n",
    "We don't know where he got those values but we can see what regression says for the relative importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "We'll use similar data we used before but cleaned up to have the just the four factors and other relevant data.\n",
    "\n",
    "Recall the two values:\n",
    "\\begin{align*}\n",
    "  \\text{Rating Ratio} & = \\frac{\\text{Off. Rating}}{\\text{Def. Rating}} \\\\\n",
    "  \\text{Log Rating Ratio} & = \\log\\text{Rating Ratio}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_teams_full = pd.read_csv('team_season_ff_data.csv')\n",
    "\n",
    "nba_teams = nba_teams_full.loc[nba_teams_full.season >= 2000]\n",
    "nba_teams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Four Factors and Winning Pct\n",
    "\n",
    "Let's first look at a model for winning percentage using the four factors.  Since winning percentage is centered around .500, we need to include a constant term to center our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_vars = 'win_pct'\n",
    "ind_vars = ['eFG', 'Tov', 'Reb', 'Ftr']\n",
    "coefs, _, _ = multiple_regression(dep_vars, ind_vars, nba_teams, constant=True)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rescale the non-intercept coefficients to sum to 100 in absolute value so they are relative percentages, as Dean Oliver used.  We got reasonably close to Dean Oliver's prescribed values but it turns out that our model suggests lower weights for **Tov**, **Reb**, and **FTR** in exchange for more importance for **eFG**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_coefs = coefs['eFG':]\n",
    "factor_coefs / factor_coefs.abs().sum() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Four Factors and the log Rating Ratio\n",
    "\n",
    "We can also look at our ole Pythagorean Expectation pal the log rating ratio.  There is no need for an intercept for the log rating ratio since it's centered very close to 0.\n",
    "\n",
    "Perhaps not shockingly, we get similar results for the relative importance.  The **eFG** factor again is more relevant according to this regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_vars = 'log_rtg_rat'\n",
    "ind_vars = ['eFG', 'Tov', 'Reb', 'Ftr']\n",
    "coefs, _, _ = multiple_regression(dep_vars, ind_vars, nba_teams)\n",
    "coefs / coefs.abs().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As before, what if only include one variable in the regression?\n",
    "\n",
    "The resulting coefficients from the misspecified models are all off, and not in a consistent direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_vars = 'log_rtg_rat'\n",
    "ind_vars = 'eFG'\n",
    "coefs_misspecified, _, _ = multiple_regression(dep_vars, ind_vars, nba_teams)\n",
    "coefs_misspecified[ind_vars], coefs[ind_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Games\n",
    "\n",
    "If you recall, the four factor model was also effective for explaning game performance.  Compared to the season level, the performance was quite similar though the games just had more variation.  The regression should still be more effective.  How does that play out here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_csv('game_ff_data_2016.csv')\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2016, the weight is just a bit more on eFG.  But it appears generally consistent with season level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_vars = 'log_rtg_rat'\n",
    "ind_vars = ['eFG', 'Tov', 'Reb', 'Ftr']\n",
    "coefs, _, _ = multiple_regression(dep_vars, ind_vars, games)\n",
    "coefs = coefs / coefs.abs().sum()\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We should be heartened by the overall stability of the regression modeling.  It's a good sign when the model is stable and not overly sensitive to changing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plus/Minus Regression\n",
    "\n",
    "We can think of a plus/minus rating as simultaneous impacts of players on team performance.  If we track performance over stints, where the same 10 players are on the court, we can measure a player's impact using a regression.\n",
    "\n",
    "The model is:\n",
    "$$\n",
    "    \\mathrm{HomeNetRating}_t = \\mathrm{HomeCourtAdv} + \\mathrm{Sum}(\\mbox{Home Player $i$'s net rating if player $i$ is on the during the $t$-th stint}) - \\mathrm{Sum}(\\mbox{Away Player $i$'s net rating if player $i$ is on the during the $t$-th stint}).\n",
    "$$\n",
    "\n",
    "Using play-by-play data from 2014-15, the stint data is collected into a table.  For each stint, possessions and scoring is tracked as well as the 10 players on the court.  There about about 40k stints over the nba season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stint data\n",
    "\n",
    "Here we can see the data on all the stints but this isn't really effective for performing a regression analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regression_helper import multiple_regression_big\n",
    "\n",
    "df = pd.read_csv('nba_stints_2015_full.csv.gz')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stint Data for Regression\n",
    "\n",
    "Instead, we use encoded data that is actually numeric.  Each player is represented by a 0 or 1.  If a player is on the court during the stint, he will have a 1.  Most of the entries will be 0.\n",
    "\n",
    "HCA naturally stands for home court advantage and is actually just a column of 1s.  This is like fitting an intercept.\n",
    "\n",
    "\n",
    "We do this via a big model where each variable corresponds to a player and is 0 if the player was _not_ on the court during the stint and 1 if he was.  This creates a table of 0s and 1s of size Number of Stints by Number of Players + 1.  The +1 is for an extra variable representing the home court advantage.  Each row will only have 10 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stints = pd.read_csv('nba_stints_2015_binary.csv.gz')\n",
    "players = list(stints.columns[3:])\n",
    "\n",
    "stints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted Plus/Minus\n",
    "\n",
    "We need a more advanced solver for the regression model that can handle this much bigger problem.  This is where `multiple_regression_big` comes in.\n",
    "\n",
    "We set `net_rtg` as the dep_var and we set `HCA` and the players as the independent vars.  We also utilize weights: each stint has a total number of possessions.  We want the results from stints with more possessions to be weighted more than other possessions.\n",
    "\n",
    "After we compute the regression model, we can see some of the results that come out for the first ten players alphabetically.  These are the _Adjusted Plus/Minus_ or APM ratings\n",
    "\n",
    "The result of this regression model is a player rating which should indicate the impact the player had on Net Rating relative to league average.  A positive value obviously indicates a positive impact on Net Rating.  We could in fact use this to construct lineup net ratings above average by summing across a lineup of players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'net_rtg'\n",
    "ind_vars = ['HCA'] + players\n",
    "apm = multiple_regression_big(dep_var, ind_vars, stints, weights='net_poss')\n",
    "apm.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the histogram plot.\n",
    "\n",
    "This is odd... there are some very large values.  This is supposed to be the player's impact on net rating and there are values over 100 in magnitude??\n",
    "\n",
    "Did we do something wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apm.plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the top ranked players.\n",
    "\n",
    "Geez, who are some of these guys?  Where's Lebron??\n",
    "\n",
    "What happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apm_HCA = apm['HCA']\n",
    "print(\"Home Court Advantage for Net Rating: {:.2f}\".format(apm_HCA))\n",
    "print()\n",
    "print(\"Top 20 by APM\\n\" + 40*\"=\")\n",
    "print(apm[players].sort_values(ascending=False)[:20].to_string())\n",
    "print()\n",
    "print(\"Bottom 20 by APM\\n\" + 40*\"=\")\n",
    "print(apm[players].sort_values(ascending=True)[:20].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalizing the Least Squares Fit: Regularized Adjusted Plus Minus (xRAPM)\n",
    "\n",
    "We just ran into a few issues:\n",
    "+ Players who we should have dropped due to not having many minutes.  If they have a raw net rating of 200 in 1 possession, the regression will still try to aggressively optimize and give that player a high rating.  We can bucket those players together or force the regression optimizer to not be so aggressive\n",
    "+ Lineups do not behave like randomized controlled trials.  Given nine players on the court, we can do a really good job predicting the tenth.  Sometimes two players almost always play together.  Or two players switch for each other.\n",
    "+ This lack of randomization leads to a condition called _multicollinearity_ and is a huge potential problem in multiple regression problems.  Due to issues that can be derived/explained with Linear Algebra, if multicollinearity is present the regression will likely falter and not be able to distinguish well what is happening.  \n",
    "\n",
    "Our solution is to use something called _penalization_ or _regularization_.\n",
    "\n",
    "Instead of just aggressively minimizing the mean square error, we reframe the regression to simultaneously minimize mean square error but penalize aggressive fitting by the optimizer.  If the optimization wants to assign a big rating alue to a player, it better have a lot of evidence behind it, ie. the reduction in the least squares needs to offset the penalty imposed.\n",
    "\n",
    "What exactly is the penalty?  We penalize the sum of squares of the coefficients and we introduce a penalty parameter that quantifies the strength of this penalty.  This parameter is our choice but there are methods (beyond the scope of this demo) that can suggest a good value.\n",
    "\n",
    "The result of this is a statistic attributed to Jerry Engelmann called _Regularized Adjusted Plus Minus_ or xRAPM.  It is actually the cousin/basis for ESPN's Real Plus/Minus statistic. \n",
    "\n",
    "We use a new function to perform this: `multiple_regression_big_with_penalty`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regression_helper import multiple_regression_big_with_penalty\n",
    "\n",
    "rapm = multiple_regression_big_with_penalty('net_rtg', ind_vars, stints, weights='net_poss', penalty=3400.)\n",
    "rapm.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks way better.  Now we see the people we expect to see at the top.  There are some interesting names at the top like Kyle Korver or Kelly Olynyk.  I certainly would have expected them to rank so high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapm.plot.hist(bins=50)\n",
    "\n",
    "rapm_HCA = rapm['HCA']\n",
    "print(\"Home Court Advantage for Net Rating: {:.2f}\".format(rapm_HCA))\n",
    "print()\n",
    "print(\"Top 20 by RAPM\\n\" + 40*\"=\")\n",
    "print(rapm[players].sort_values(ascending=False)[:20].to_string())\n",
    "print()\n",
    "print(\"Bottom 20 by RAPM\\n\" + 40*\"=\")\n",
    "print(rapm[players].sort_values(ascending=True)[:20].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How penalizing the coefficients cleans things up\n",
    "\n",
    "Let's take a look at some Grizzlies players.  Of particular interest is Kosta Koufos and Marc Gasol.  They are both centers who rarely played together but combined covered most of the possessions at center for the grizzlies.\n",
    "\n",
    "We shouldn't be so outright dismissive of the APM results just because these three players look \"off\".  But one thing you can see is how the gap between Koufos and Gasol was shrunk in half (and of course they went from negative to positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apm[\"Kosta Koufos\"], apm[\"Marc Gasol\"], apm[\"Zach Randolph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapm[\"Kosta Koufos\"], rapm[\"Marc Gasol\"], rapm[\"Zach Randolph\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at all Grizzly players, you see how the ratings are cleaned up a lot.  Note that not all of the relative positionings are the same.  Some players went from negative to positive, some switched order.  This suggests we're doing what we want to do: not just contract everyone's rating towards 0 but find a result that is more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "griz_players = ['Jordan Adams', 'Tony Allen', 'Nick Calathes', 'Vince Carter',\n",
    "       'Mike Conley', 'Marc Gasol', 'JaMychal Green', 'Jeff Green',\n",
    "       'Kosta Koufos', 'Courtney Lee', 'Jon Leuer', 'Kalin Lucas',\n",
    "       'Quincy Pondexter', 'Tayshaun Prince', 'Zach Randolph',\n",
    "       'Russ Smith', 'Jarnell Stokes', 'Tyrus Thomas', 'Beno Udrih']\n",
    "apm[griz_players]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapm[griz_players]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to ESPN's RPM\n",
    "\n",
    "We can compare our results ESPN's Real Plus/Minus statistic.\n",
    "\n",
    "Compared against overall RPM from 2014-15, our rating is actually that not that bad.  We're overrating players a bit and maybe using more years would help.  RPM actually uses box score data and some biographic data to help stabilize the regression further.  We are working purely with lineup data so if they are doing things well, that extra data will improve things for them.\n",
    "\n",
    "Also note that ESPN produces Offensive RPM and Defensive RPM. To do this, we need to break up the stint data into offense and defense performance and have _two_ effects for each player, one for offense and one for defense.\n",
    "\n",
    "They also convert RPM to Wins, presumably using something like the pythagorean expectation formula.  Kevin Pelton's WARP statistic does similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm = pd.read_csv('rpm.csv', index_col='RK')\n",
    "rpm"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
